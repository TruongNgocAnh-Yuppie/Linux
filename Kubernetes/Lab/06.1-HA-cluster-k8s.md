# Cấu hình HA cluster k8s

Mô hình LAB

|Server|IP|etcd|Master|Worker|HAproxy|
|--------|------------|-----|-------|-------|--------|
|server01|10.10.10.221|etcd1|master1|worker1|HAproxy1|
|server02|10.10.10.222|etcd2|master2|worker2|HAproxy2|
|server03|10.10.10.223|etcd3|master3|worker3||


## 1. Cài đặt, cấu hình HAproxy+keepalived

Thực hiện trên 2 Node: 10.10.10.221, 10.10.10.222

**Enable VIP:**
```sh
vim /etc/sysctl.conf
net.ipv4.ip_nonlocal_bind=1
sysctl -p
```
**Install Haproxy, keepalived:**
```sh
yum install haproxy keepalived -y
```
**Setup keepalived configuration:**
```sh
mkdir -p /etc/keepalived
cat > /etc/keepalived/keepalived.conf <<EOF

vrrp_script check_haproxy {
script "killall -0 haproxy"
interval 3
weight 3
}

vrrp_instance LAN_133 {
interface ens33
virtual_router_id 133
priority 133
advert_int 2

authentication {
  auth_type PASS
  auth_pass ahihi
}

track_script {
  check_haproxy
}

virtual_ipaddress {
  10.10.10.220/24
  }
}

EOF
```
**Setup Haproxy**
```sh
cat > /etc/haproxy/haproxy.cfg <<EOF
global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# Default ciphers to use on SSL-enabled listening sockets.
	# For more information, see ciphers(1SSL). This list is from:
	#  https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
	ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS
	ssl-default-bind-options no-sslv3

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http

frontend k8s
bind 10.10.10.220:6445
option tcplog
mode tcp
default_backend k8s-master-nodes


backend k8s-master-nodes
mode tcp
balance roundrobin
option tcp-check
server k8s-master-1 10.10.10.221:6443 check fall 3 rise 2
server k8s-master-2 10.10.10.222:6443 check fall 3 rise 2
server k8s-master-3 10.10.10.223:6443 check fall 3 rise 2

EOF
```
**Thực hiện restart haproxy và keepalived:**
```sh
systemctl restart haproxy
systemctl restart keepalived
```
**Kiểm tra:**
```sh
ip a | grep ens33
2: ens33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    inet 10.10.10.221/24 brd 10.10.10.255 scope global noprefixroute dynamic ens33
    inet 10.10.10.220/24 scope global secondary ens33
```
## 2. Cài đặt, cấu hình HA Etcd cluster:

## 3. Cài đặt, cấu hình master node k8s và worker node k8s:
### 3.1 Thực hiện trên 3 Node Master và 3 Node Worker

Xem chi tiết cài đặt [tại đây](https://github.com/quangln94/Linux/blob/master/Kubernetes/Lab/00-Install-k8s.md)

Disable swap:
```sh
$ swapoff -a
$ vim /etc/fstab
#/dev/mapper/cl-swap swap swap defaults 0 0
```
```sh
$ cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
$ sysctl --system
```
Tắt firewalld và SElinux
```sh
systemctl stop firewalld
systemctl disable firewalld
sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
```
Cài đặt Kubeadm
```sh
$ cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-$basearch
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
$ yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
$ systemctl enable kubelet
```
Cài đặt Docker
```sh
yum -y install docker
systemctl start docker
systemctl enable docker
```
### 3.2 Thực hiện trên từng Node
**Thực hiện trên Node Master 1:**

***Copy cert to /etc/kubernetes/pki:***
```sh
mkdir -p /etc/kubernetes/pki/etcd
cp /etc/etcd/ca.pem /etc/kubernetes/pki/etcd/
cp /etc/etcd/kubernetes.pem /etc/kubernetes/pki/
cp /etc/etcd/kubernetes-key.pem /etc/kubernetes/pki/
```
Tạo file `kubeadm-config.yaml` trên Node Master-1 (etcd1):
```sh
apiVersion: kubeadm.k8s.io/v1beta1
kind: ClusterConfiguration
kubernetesVersion: stable
controlPlaneEndpoint: "10.10.10.220:6445"
etcd:
    external:
        endpoints:
        - https://10.10.10.221:2379
        - https://10.10.10.222:2379
        - https://10.10.10.223:2379
        caFile: /etc/kubernetes/pki/etcd/ca.pem
        certFile: /etc/kubernetes/pki/kubernetes.pem
        keyFile: /etc/kubernetes/pki/kubernetes-key.pem
networking:
    podSubnet: "10.244.0.0/16"
```
***Thực hiện khởi tạo node master đầu tiên trong cụm k8s:***
```sh
kubeadm init --config=kubeadm-config.yaml
```
Trong output ở trên có các dòng sau, sử dụng để join các node master và các node worker vào cụm cluster ở phần dưới:
```sh
kubeadm join 172.16.68.215:6445 --token dzvrxa.3m8ajhpiycj3btek --discovery-token-ca-cert-hash sha256:d770d2a3e3494fcc090641de61 --experimental-control-plane --certificate-key 635054d25d49336bdd9022ceebe447

kubeadm join 172.16.68.215:6445 --token dzvrxa.3m8ajhpiycj3btek --discovery-token-ca-cert-hash sha256:d770d2a3e3494fcc090641de61e005b2b6d8
```
***Khởi tạo môi trường:***
```sh
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
```
***Configure Pod Network with Flannel***
```sh
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```
***Join các node master vào cụm k8s, thực hiện trên 2 node master2 và master3:***
```sh
kubeadm join 172.16.68.215:6445 --token dzvrxa.3m8ajhpiycj3btek     --discovery-token-ca-cert-hash sha256:d770d2a3e3494fcc090641de61     --experimental-control-plane --certificate-key 635054d25d49336bdd9022ceebe44

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
```
***Để thực hiện 1 node vừa làm master và worker, ta cần thực hiện lệnh sau:***
```sh
kubectl taint nodes --all node-role.kubernetes.io/master-

kubectl get node -o wide
NAME       STATUS   ROLES    AGE   VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
master-1   Ready    master   5d    v1.14.1   172.16.68.210   <none>        Ubuntu 18.04.2 LTS   4.15.0-50-generic   docker://18.9.2
master-2   Ready    master   5d    v1.14.1   172.16.68.211   <none>        Ubuntu 18.04.2 LTS   4.15.0-48-generic   docker://18.9.2
master-3   Ready    master   5d    v1.14.1   172.16.68.212   <none>        Ubuntu 18.04.2 LTS   4.15.0-50-generic   docker://18.9.2
```
***Check các pod trong namespace kube-system:***
```sh
root@master-1:~# kubectl get pod -n kube-system
NAME                               READY   STATUS    RESTARTS   AGE
coredns-fb8b8dccf-b2wwb            1/1     Running   0          79m
coredns-fb8b8dccf-z9d5h            1/1     Running   0          79m
kube-apiserver-master-1            1/1     Running   0          78m
kube-apiserver-master-2            1/1     Running   0          76m
kube-apiserver-master-3            1/1     Running   0          76m
kube-controller-manager-master-1   1/1     Running   0          78m
kube-controller-manager-master-2   1/1     Running   0          76m
kube-controller-manager-master-3   1/1     Running   0          76m
kube-flannel-ds-amd64-mbmhw        1/1     Running   0          76m
kube-flannel-ds-amd64-pc4gb        1/1     Running   0          12m
kube-flannel-ds-amd64-pfnr2        1/1     Running   0          77m
kube-flannel-ds-amd64-rgd2q        1/1     Running   0          76m
kube-flannel-ds-amd64-th5v5        1/1     Running   0          13m
kube-flannel-ds-amd64-ttkzk        1/1     Running   0          13m
kube-proxy-7nk98                   1/1     Running   0          13m
kube-proxy-8mtwq                   1/1     Running   0          13m
kube-proxy-bf5zd                   1/1     Running   0          76m
kube-proxy-h9h8f                   1/1     Running   0          12m
kube-proxy-z8wgf                   1/1     Running   0          76m
kube-proxy-zzt96                   1/1     Running   0          79m
kube-scheduler-master-1            1/1     Running   0          78m
kube-scheduler-master-2            1/1     Running   0          76m
kube-scheduler-master-3            1/1     Running   0          76m
```
***Chú ý: Mặc định, trong cụm k8s khi 1 node worker down thì thời gian các pods trên node đó tự động được tạo lại trên node worker khác là 5'. Ta có thể giảm thời gian này xuống, để các pods được tạo lại trên node worker khác nhanh hơn (ở đây tôi set khoảng thời gian này = 1') bằng cách thực hiện các bước sau:***

- ***Bước 1: Thêm `--pod-eviction-timeout=30s` vào file `/etc/kubernetes/manifests/kube-controller-manager.yaml`***
```sh
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --bind-address=127.0.0.1
    - --pod-eviction-timeout=30s
	...
```  
- ***Bước 2: Thêm `default-not-ready-toleration-seconds=30` và `default-unreachable-toleration-seconds=30` vào file `/etc/kubernetes/manifests/kube-apiserver.yaml` (thực hiện đối với k8s từ phiên bản từ 1.11 trở lên)***
```sh
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=172.168.68.210
    - --default-not-ready-toleration-seconds=30
    - --default-unreachable-toleration-seconds=30
    - --allow-privileged=true
    ...
```
## Tài liệu hướng dẫn
- https://github.com/thangtq710/Kubernetes/blob/master/docs/3.Install_HA_cluster_K8s.md
